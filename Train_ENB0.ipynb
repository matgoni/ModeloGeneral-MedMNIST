{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c15e78f",
   "metadata": {},
   "source": [
    "# Entrenamiento de ResNet-18 con todos los conjuntos de MedMNIST\n",
    "\n",
    "Este cuaderno prepara y entrena un modelo ResNet-18 capaz de clasificar de forma conjunta todos los conjuntos de MedMNIST. El flujo reutiliza el módulo `scripts/entrenar_resnet_general.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b1d47",
   "metadata": {},
   "source": [
    "## Flujo de trabajo\n",
    "- Importar utilidades y fijar una configuración reproducible\n",
    "- Listar los datasets disponibles y definir la configuración de entrenamiento\n",
    "- Preparar los *DataLoaders* combinando todos los conjuntos\n",
    "- Construir el modelo ResNet-18 y los objetos de optimización\n",
    "- Entrenar el modelo con seguimiento de métricas por época\n",
    "- Evaluar en el conjunto de prueba y generar un reporte reutilizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eead5fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de PyTorch: 2.8.0+cpu\n",
      "CUDA disponible: False\n"
     ]
    }
   ],
   "source": [
    "# Importaciones y configuración básica\n",
    "import json\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "\n",
    "from medmnist import INFO\n",
    "\n",
    "from scripts.Train_EN2 import (\n",
    "    crear_cargadores,\n",
    "    construir_modelo,\n",
    "    recorrer_entrenamiento,\n",
    "    evaluar_modelo,\n",
    "    guardar_reporte,\n",
    "    construir_scheduler,\n",
    "    nn,\n",
    "    Adam,\n",
    ")\n",
    "\n",
    "# Fijamos semillas para reproducibilidad básica\n",
    "TORCH_SEED = 42\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(TORCH_SEED)\n",
    "\n",
    "print(f\"Versión de PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01153e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de datasets 2D: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bloodmnist',\n",
       " 'breastmnist',\n",
       " 'chestmnist',\n",
       " 'dermamnist',\n",
       " 'octmnist',\n",
       " 'organamnist',\n",
       " 'organcmnist',\n",
       " 'organsmnist',\n",
       " 'pathmnist',\n",
       " 'pneumoniamnist',\n",
       " 'retinamnist',\n",
       " 'tissuemnist']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listado de datasets 2D de MedMNIST\n",
    "# Filtramos los que no tienen '3d' en el nombre de su clase de Python\n",
    "todos_los_datasets = sorted(\n",
    "    nombre\n",
    "    for nombre, info in INFO.items()\n",
    "    if '3d' not in nombre.lower() and '3d' not in info.get('python_class', '').lower()\n",
    ")\n",
    "print(f\"Total de datasets 2D: {len(todos_los_datasets)}\")\n",
    "todos_los_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9c3e12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(datasets=['bloodmnist',\n",
       "                    'breastmnist',\n",
       "                    'chestmnist',\n",
       "                    'dermamnist',\n",
       "                    'octmnist',\n",
       "                    'organamnist',\n",
       "                    'organcmnist',\n",
       "                    'organsmnist',\n",
       "                    'pathmnist',\n",
       "                    'pneumoniamnist',\n",
       "                    'retinamnist',\n",
       "                    'tissuemnist'],\n",
       "          epocas=5,\n",
       "          tamano_lote=256,\n",
       "          tasa_aprendizaje=0.001,\n",
       "          decaimiento_peso=0.0001,\n",
       "          tamano_imagen=28,\n",
       "          usar_aumentos=True,\n",
       "          descargar=True,\n",
       "          sin_preentrenar=False,\n",
       "          dispositivo='cpu',\n",
       "          salida='resultados/reporte_efficientnet_todos.json',\n",
       "          trabajadores=4,\n",
       "          scheduler='plateau',\n",
       "          factor_scheduler=0.5,\n",
       "          paciencia_scheduler=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración centralizada; ajusta hiperparámetros aquí\n",
    "config = SimpleNamespace(\n",
    "    datasets=todos_los_datasets,\n",
    "    epocas=5,  # Incrementa si quieres un entrenamiento más largo\n",
    "    tamano_lote=256,\n",
    "    tasa_aprendizaje=1e-3,\n",
    "    decaimiento_peso=1e-4,\n",
    "    tamano_imagen=28,\n",
    "    usar_aumentos=True,\n",
    "    descargar=True,\n",
    "    sin_preentrenar=False,\n",
    "    dispositivo=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    salida=\"resultados/reporte_efficientnet_todos.json\",\n",
    "    trabajadores=4,\n",
    "    scheduler=\"plateau\",\n",
    "    factor_scheduler=0.5,\n",
    "    paciencia_scheduler=3,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fada69",
   "metadata": {},
   "source": [
    "## Preparar *DataLoaders* combinando todos los conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e243d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de muestras por partición: {'train': 518175, 'test': 119320, 'val': 70467}\n",
      "Total de clases combinadas: 92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bloodmnist': RegistroDataset(nombre='bloodmnist', indice_inicial=0, clases=8),\n",
       " 'breastmnist': RegistroDataset(nombre='breastmnist', indice_inicial=8, clases=2),\n",
       " 'chestmnist': RegistroDataset(nombre='chestmnist', indice_inicial=10, clases=14),\n",
       " 'dermamnist': RegistroDataset(nombre='dermamnist', indice_inicial=24, clases=7),\n",
       " 'octmnist': RegistroDataset(nombre='octmnist', indice_inicial=31, clases=4),\n",
       " 'organamnist': RegistroDataset(nombre='organamnist', indice_inicial=35, clases=11),\n",
       " 'organcmnist': RegistroDataset(nombre='organcmnist', indice_inicial=46, clases=11),\n",
       " 'organsmnist': RegistroDataset(nombre='organsmnist', indice_inicial=57, clases=11),\n",
       " 'pathmnist': RegistroDataset(nombre='pathmnist', indice_inicial=68, clases=9),\n",
       " 'pneumoniamnist': RegistroDataset(nombre='pneumoniamnist', indice_inicial=77, clases=2),\n",
       " 'retinamnist': RegistroDataset(nombre='retinamnist', indice_inicial=79, clases=5),\n",
       " 'tissuemnist': RegistroDataset(nombre='tissuemnist', indice_inicial=84, clases=8)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    loader_entrenamiento,\n",
    "    loader_validacion,\n",
    "    loader_prueba,\n",
    "    info_datasets,\n",
    ") = crear_cargadores(\n",
    "    nombres_dataset=config.datasets,\n",
    "    tamano_lote=config.tamano_lote,\n",
    "    descarga=config.descargar,\n",
    "    tamano_imagen=config.tamano_imagen,\n",
    "    usar_aumentos=config.usar_aumentos,\n",
    "    trabajadores=config.trabajadores,\n",
    ")\n",
    "\n",
    "resumen_datos = {\n",
    "    \"train\": len(loader_entrenamiento.dataset),\n",
    "    \"test\": len(loader_prueba.dataset),\n",
    "}\n",
    "if loader_validacion is not None:\n",
    "    resumen_datos[\"val\"] = len(loader_validacion.dataset)\n",
    "\n",
    "print(\"Resumen de muestras por partición:\", resumen_datos)\n",
    "\n",
    "total_clases = sum(info.clases for info in info_datasets.values())\n",
    "print(\"Total de clases combinadas:\", total_clases)\n",
    "\n",
    "info_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ceae5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def construir_modelo(total_clases: int, usar_pesos_imagenet: bool) -> nn.Module:\n",
      "    \"\"\"Inicializa la Efficient-BO ajustando la capa de salida al número total de clases.\"\"\"\n",
      "    if usar_pesos_imagenet:\n",
      "        pesos = EfficientNet_B0_Weights.DEFAULT\n",
      "        modelo = efficientnet_b0(weights=pesos)\n",
      "    else:\n",
      "        modelo = efficientnet_b0(weights=None)\n",
      "    #caracteristicas = modelo.fc.in_features\n",
      "    #modelo.fc = nn.Linear(caracteristicas, total_clases)\n",
      "    #return modelo\n",
      "    # EfficientNet-B0 tiene la cabeza en classifier[1]\n",
      "    in_features = modelo.classifier[1].in_features\n",
      "    modelo.classifier[1] = nn.Linear(in_features, total_clases)\n",
      "    return modelo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from scripts.Train_EN2 import construir_modelo\n",
    "print(inspect.getsource(construir_modelo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2300b788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts.Train_EN2' from 'e:\\\\ModeloGeneral-MedMNIST\\\\scripts\\\\Train_EN2.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import scripts.Train_EN2\n",
    "importlib.reload(scripts.Train_EN2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e5aedb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"grep\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!grep -R \"ResNet\" -n e:/ModeloGeneral-MedMNIST/scripts/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d9275",
   "metadata": {},
   "source": [
    "## Construir modelo, criterio de pérdida y optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b00158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\estef/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.5M/20.5M [00:02<00:00, 8.29MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=92, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispositivo = torch.device(config.dispositivo)\n",
    "print(f\"Usando dispositivo: {dispositivo}\")\n",
    "\n",
    "modelo = construir_modelo(\n",
    "    total_clases=total_clases,\n",
    "    usar_pesos_imagenet=not config.sin_preentrenar,\n",
    ")\n",
    "modelo = modelo.to(dispositivo)\n",
    "\n",
    "criterio = nn.CrossEntropyLoss()\n",
    "optimizador = Adam(\n",
    "    modelo.parameters(),\n",
    "    lr=config.tasa_aprendizaje,\n",
    "    weight_decay=config.decaimiento_peso,\n",
    ")\n",
    "scheduler = construir_scheduler(\n",
    "    optimizador=optimizador,\n",
    "    tipo_scheduler=config.scheduler,\n",
    "    factor=config.factor_scheduler,\n",
    "    paciencia=config.paciencia_scheduler,\n",
    ")\n",
    "\n",
    "modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6467809",
   "metadata": {},
   "source": [
    "## Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06fad0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\estef\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoca 001] Perdida ent: 0.9508 | Exactitud ent: 0.6881 | Perdida val: 0.8010 | Exactitud val: 0.7310\n",
      "[Epoca 002] Perdida ent: 0.7942 | Exactitud ent: 0.7338 | Perdida val: 0.7762 | Exactitud val: 0.7396\n",
      "[Epoca 003] Perdida ent: 0.7656 | Exactitud ent: 0.7434 | Perdida val: 0.7345 | Exactitud val: 0.7548\n",
      "[Epoca 004] Perdida ent: 0.7446 | Exactitud ent: 0.7493 | Perdida val: 0.7340 | Exactitud val: 0.7560\n",
      "[Epoca 005] Perdida ent: 0.7289 | Exactitud ent: 0.7549 | Perdida val: 0.7049 | Exactitud val: 0.7615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoca': 1,\n",
       "  'perdida_entrenamiento': 0.9508099685430975,\n",
       "  'exactitud_entrenamiento': 0.6881458966565349,\n",
       "  'perdida_validacion': 0.8009700593017657,\n",
       "  'exactitud_validacion': 0.7309520768586715},\n",
       " {'epoca': 2,\n",
       "  'perdida_entrenamiento': 0.794237363373554,\n",
       "  'exactitud_entrenamiento': 0.7338119361219665,\n",
       "  'perdida_validacion': 0.7762133454732437,\n",
       "  'exactitud_validacion': 0.739551846963827},\n",
       " {'epoca': 3,\n",
       "  'perdida_entrenamiento': 0.7655880914974668,\n",
       "  'exactitud_entrenamiento': 0.7433897814444926,\n",
       "  'perdida_validacion': 0.7344641606144933,\n",
       "  'exactitud_validacion': 0.7547930236848454}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historial_entrenamiento, mejor_estado = recorrer_entrenamiento(\n",
    "    modelo=modelo,\n",
    "    cargador_entrenamiento=loader_entrenamiento,\n",
    "    cargador_validacion=loader_validacion,\n",
    "    criterio=criterio,\n",
    "    optimizador=optimizador,\n",
    "    scheduler=scheduler,\n",
    "    epocas=config.epocas,\n",
    "    dispositivo=dispositivo,\n",
    ")\n",
    "\n",
    "# Si hubo mejora en validación, recargamos el mejor estado\n",
    "if mejor_estado:\n",
    "    modelo.load_state_dict(mejor_estado)\n",
    "\n",
    "historial_entrenamiento[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4476817",
   "metadata": {},
   "source": [
    "## Historial de métricas por época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d085417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoca</th>\n",
       "      <th>perdida_entrenamiento</th>\n",
       "      <th>exactitud_entrenamiento</th>\n",
       "      <th>perdida_validacion</th>\n",
       "      <th>exactitud_validacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.950810</td>\n",
       "      <td>0.688146</td>\n",
       "      <td>0.800970</td>\n",
       "      <td>0.730952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.794237</td>\n",
       "      <td>0.733812</td>\n",
       "      <td>0.776213</td>\n",
       "      <td>0.739552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.765588</td>\n",
       "      <td>0.743390</td>\n",
       "      <td>0.734464</td>\n",
       "      <td>0.754793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.744585</td>\n",
       "      <td>0.749334</td>\n",
       "      <td>0.733999</td>\n",
       "      <td>0.756028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.728866</td>\n",
       "      <td>0.754926</td>\n",
       "      <td>0.704937</td>\n",
       "      <td>0.761505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoca  perdida_entrenamiento  exactitud_entrenamiento  perdida_validacion  \\\n",
       "0      1               0.950810                 0.688146            0.800970   \n",
       "1      2               0.794237                 0.733812            0.776213   \n",
       "2      3               0.765588                 0.743390            0.734464   \n",
       "3      4               0.744585                 0.749334            0.733999   \n",
       "4      5               0.728866                 0.754926            0.704937   \n",
       "\n",
       "   exactitud_validacion  \n",
       "0              0.730952  \n",
       "1              0.739552  \n",
       "2              0.754793  \n",
       "3              0.756028  \n",
       "4              0.761505  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historial = pd.DataFrame(historial_entrenamiento)\n",
    "df_historial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d72720",
   "metadata": {},
   "source": [
    "## Evaluación en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63ed1355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\estef\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud global en test: 0.6936\n",
      "Pérdida global en test: 0.9389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>exactitud</th>\n",
       "      <th>ejemplos</th>\n",
       "      <th>offset</th>\n",
       "      <th>clases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bloodmnist</td>\n",
       "      <td>0.907045</td>\n",
       "      <td>3421</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>organamnist</td>\n",
       "      <td>0.870795</td>\n",
       "      <td>17778</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pneumoniamnist</td>\n",
       "      <td>0.863782</td>\n",
       "      <td>624</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pathmnist</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>7180</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breastmnist</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>156</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>organcmnist</td>\n",
       "      <td>0.661879</td>\n",
       "      <td>8216</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dermamnist</td>\n",
       "      <td>0.647880</td>\n",
       "      <td>2005</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tissuemnist</td>\n",
       "      <td>0.639425</td>\n",
       "      <td>47280</td>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>organsmnist</td>\n",
       "      <td>0.635777</td>\n",
       "      <td>8827</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chestmnist</td>\n",
       "      <td>0.627914</td>\n",
       "      <td>22433</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>octmnist</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>retinamnist</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>400</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset  exactitud  ejemplos  offset  clases\n",
       "0       bloodmnist   0.907045      3421       0       8\n",
       "5      organamnist   0.870795     17778      35      11\n",
       "9   pneumoniamnist   0.863782       624      77       2\n",
       "8        pathmnist   0.850000      7180      68       9\n",
       "1      breastmnist   0.698718       156       8       2\n",
       "6      organcmnist   0.661879      8216      46      11\n",
       "3       dermamnist   0.647880      2005      24       7\n",
       "11     tissuemnist   0.639425     47280      84       8\n",
       "7      organsmnist   0.635777      8827      57      11\n",
       "2       chestmnist   0.627914     22433      10      14\n",
       "4         octmnist   0.594000      1000      31       4\n",
       "10     retinamnist   0.405000       400      79       5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perdida_test, exactitud_test, metricas_por_dataset = evaluar_modelo(\n",
    "    modelo,\n",
    "    loader_prueba,\n",
    "    criterio,\n",
    "    dispositivo,\n",
    ")\n",
    "\n",
    "print(f\"Exactitud global en test: {exactitud_test:.4f}\")\n",
    "print(f\"Pérdida global en test: {perdida_test:.4f}\")\n",
    "\n",
    "filas = []\n",
    "for nombre, datos in metricas_por_dataset.items():\n",
    "    filas.append(\n",
    "        {\n",
    "            \"dataset\": nombre,\n",
    "            \"exactitud\": datos.get(\"exactitud\", 0.0),\n",
    "            \"ejemplos\": int(datos.get(\"ejemplos\", 0)),\n",
    "            \"offset\": info_datasets[nombre].indice_inicial,\n",
    "            \"clases\": info_datasets[nombre].clases,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_metricas = pd.DataFrame(filas).sort_values(\"exactitud\", ascending=False)\n",
    "df_metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46faaca1",
   "metadata": {},
   "source": [
    "## Guardar reporte y revisar el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d947fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte guardado en: E:\\ModeloGeneral-MedMNIST\\resultados\\reporte_efficientnet_todos.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fecha', 'configuracion', 'historial_epocas', 'metricas_prueba', 'datasets'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas_reporte = {\n",
    "    \"perdida\": perdida_test,\n",
    "    \"exactitud\": exactitud_test,\n",
    "    \"detalle_por_dataset\": df_metricas.set_index(\"dataset\")[['exactitud', 'ejemplos']].to_dict(orient=\"index\"),\n",
    "}\n",
    "\n",
    "ruta_reporte = Path(config.salida)\n",
    "\n",
    "guardar_reporte(\n",
    "    ruta_salida=ruta_reporte,\n",
    "    argumentos=config,\n",
    "    historial=historial_entrenamiento,\n",
    "    metricas_prueba=metricas_reporte,\n",
    "    informacion_datasets=info_datasets,\n",
    ")\n",
    "\n",
    "print(f\"Reporte guardado en: {ruta_reporte.resolve()}\")\n",
    "\n",
    "with ruta_reporte.open(\"r\", encoding=\"utf-8\") as archivo:\n",
    "    resumen = json.load(archivo)\n",
    "resumen.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
